{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b97b3b00-8ff4-4e1b-b7c7-709f87aabc37",
   "metadata": {},
   "source": [
    "## Allowing language models to choose the right algorithm\n",
    "In this notebook we enable a language model to choose for the right algorithm. We define multiple segmentation algorithms / tools and then give the language model the choice which one to use given different inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4ae3a80-b6ea-4409-95b7-caecd4e4211c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'napari_segment_blobs_and_things_with_membranes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tool\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m imread\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnapari_segment_blobs_and_things_with_membranes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m voronoi_otsu_labeling, local_minima_seeded_watershed\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstackview\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'napari_segment_blobs_and_things_with_membranes'"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.tools import tool\n",
    "\n",
    "from skimage.io import imread\n",
    "from napari_segment_blobs_and_things_with_membranes import voronoi_otsu_labeling, local_minima_seeded_watershed\n",
    "\n",
    "import stackview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b78c8e5-58d1-4750-b659-e639a2b99d2f",
   "metadata": {},
   "source": [
    "Again, we define an image storage and a list of tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8158b6-5a36-4cad-a28f-42cd375a0d4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_storage = {}\n",
    "tools = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5b05a7-8ef6-458f-acbf-1c79e26cf9fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tools.append\n",
    "@tool\n",
    "def load_image(filename:str):\n",
    "    \"\"\"Useful for loading and image file and storing it.\"\"\"\n",
    "    print(\"loading\", filename)\n",
    "    image = imread(filename)\n",
    "    image_storage[filename] = image\n",
    "    return \"The image is now stored as \" + filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf722d8-5636-4cfc-a3c7-422e0f02fe68",
   "metadata": {},
   "source": [
    "We define two segmentation algorithms, one for segmenting bright objects and one for segmenting dark objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993a17aa-57b2-4e72-b546-0ec7199c40c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tools.append\n",
    "@tool\n",
    "def segment_bright_objects(image_name):\n",
    "    \"\"\"\n",
    "    Useful for segmenting bright objects in an image \n",
    "    that has been loaded and stored before.\n",
    "    \"\"\"\n",
    "    print(\"segmenting (Voronoi-Otsu-Labeling)\", image_name)\n",
    "    \n",
    "    image = image_storage[image_name]\n",
    "    label_image = voronoi_otsu_labeling(image, spot_sigma=4)\n",
    "    \n",
    "    label_image_name = \"segmented_\" + image_name\n",
    "    image_storage[label_image_name] = label_image\n",
    "    \n",
    "    return \"The segmented image has been stored as \" + label_image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de6cb09-06a3-4e68-a685-0512e3f5aad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tools.append\n",
    "@tool\n",
    "def segment_dark_objects(image_name):\n",
    "    \"\"\"\n",
    "    Useful for segmenting dark objects with bright border in an image \n",
    "    that has been loaded and stored before.\n",
    "    \"\"\"\n",
    "    print(\"segmenting (Local-minima-seeded watershed)\", image_name)\n",
    "    \n",
    "    image = image_storage[image_name]\n",
    "    label_image = local_minima_seeded_watershed(image, spot_sigma=10)\n",
    "    \n",
    "    label_image_name = \"segmented_\" + image_name\n",
    "    image_storage[label_image_name] = label_image\n",
    "    \n",
    "    return \"The segmented image has been stored as \" + label_image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11fe914-4162-4ca3-b067-e5278711e3f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tools.append\n",
    "@tool\n",
    "def show_image(image_name):\n",
    "    \"\"\"Useful for showing an image that has been loaded and stored before.\"\"\"\n",
    "    print(\"showing\", image_name)\n",
    "    \n",
    "    image = image_storage[image_name]\n",
    "    display(stackview.insight(image))\n",
    "    \n",
    "    return \"The image \" + image_name + \" is shown above.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0524eb1-7633-45e7-982b-1c2cc5af0b16",
   "metadata": {},
   "source": [
    "We create some memory and a large language model based on OpenAI's chatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d032bf0-49d1-42d4-9654-394a9e660996",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "llm=ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bda4152-8cd8-4257-8e7a-e31fca49ffad",
   "metadata": {
    "tags": []
   },
   "source": [
    "Given the list of tools, the large language model and the memory, we can create an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28afdf8e-87f2-44a7-9f8d-ef188e0f13b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION, \n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e3065d-8d55-46dc-b160-ff4349ee3beb",
   "metadata": {
    "tags": []
   },
   "source": [
    "This agent can then respond to prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf8d165-de48-4052-8121-d0bedac8a3e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent.run(\"Please load the image ../../data/membrane2d.tif and show it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a78de42-7960-43f0-a62b-98106e57e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"Please segment the image ../../data/membrane2d.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae00622c-0d17-4d73-adfc-3a0622024ea4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent.run(\"Please show the segmented ../../data/membrane2d.tif image.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48dd0a0-f41c-4804-88b6-35ad766455aa",
   "metadata": {},
   "source": [
    "The segmentation does not look like a cell-segmentation. Thus, we should ask more specifically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0303b77-899a-4e8c-9d6e-f1e5136ce636",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent.run(\"Please segment the image ../../data/membrane2d.tif again and this time, segment the dark cells surrounded by bright membranes. Also show the result of the segmentation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497b2640-050a-4aef-9ab0-d5fe8fb04925",
   "metadata": {},
   "source": [
    "We can also ask the agent which algorithm it chose and why it chose this tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5c4ca0-e169-412a-85eb-46b9646750b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent.run(\"Which algorithm did you use this time?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47b9578-a60f-4708-a501-9da81baa57e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent.run(\"Why did you use this algorithm?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b93a57-f920-43c7-ae01-60dea0a09af1",
   "metadata": {},
   "source": [
    "Note: The language model cannot see the image. Its tool selection depends on information you provided and information it acquired during the chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a08e291-421b-4e69-b429-625ea362eb86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
